import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
import numpy as np


news_rss_url = {
    '매일경제' : 'https://www.mk.co.kr/rss/50200011/',
    '한국경제' : 'https://www.hankyung.com/feed/finance' 
}


class Article :
    def __init__(self, *, media, datetime, title, content):
        self.media = media
        self.datetime = datetime
        self.title = title
        self.content = content


def get_news_rss(media, url) :    
    article_list = [] # 기사 목록
    title_list = []  # 기사 제목 목록
    link_list = []   # 기사 링크 목록
    news_data = []   # 기사 본문 목록
    news_datetime = [] # 기사 작성일시 목록

    headers = {
        'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36'
    }    
    news_rss = requests.get(url,headers)
    news_rss_soup = BeautifulSoup(news_rss.content,'xml')
    # 기사 제목 
    title_list = news_rss_soup.select('item > title')
    title_list = [title.text for title in title_list]
    # 기사 상세링크 
    link_list = news_rss_soup.select('item > link')
    link_list = [link.text for link in link_list]
    # 기사 내용, 기사 작성일시
    for link in link_list :
        news_res = requests.get(link, headers=headers)
        news_content_soup = BeautifulSoup(news_res.content, 'lxml')

        try:
            if media == '매일경제':
                news_content = news_content_soup.select_one('.news_cnt_detail_wrap')
                news_data.append(news_content.text)
                news_datetime.append(news_content_soup.select_one('.time_area .registration dd').text)    
            elif media == '한국경제':
                news_content = news_content_soup.select_one('#articletxt')
                news_data.append(news_content.text)
                news_datetime.append(news_content_soup.select_one('.datetime > .item > .txt-date').text)    
        except Exception as e:
            print(len(news_data),link)
            print(e)
            
    # print(title_list)
    # print(news_data)
    # print(news_datetime)
    print(len(title_list), len(news_data), len(news_datetime))
    for item in zip(title_list, news_data, news_datetime):
        # print(media, item[0],item[1],item[2])
        article = Article(media = media, title=item[0], content=item[1], datetime=item[2])
        article_list.append(article)    
    
    return article_list


# 모든 언론사 기사를 합치기
all_article_list = []
for media, url in news_rss_url.items():
    print(media,url)
    all_article_list.append(get_news_rss(media,url))
print(len(all_article_list))


result = np.array(all_article_list).flatten().tolist()
print(len(result))
print(type(result))


data = {
    '언론사' : [ article.media for article in result ],
    '제목' : [ article.title for article in result ],
    '내용' : [ article.content for article in result ],
    '작성일시' : [ article.datetime for article in result ],
}


df = pd.DataFrame(data)


df.head(3)


# 날짜는 파이썬 표준라이브러리 datetime 사용
import datetime
# 오늘 날짜 구하기
today = datetime.datetime.today()
today = today.strftime('%Y-%m-%d')
today


df.to_csv(f'news_{today}.csv',index=False)






