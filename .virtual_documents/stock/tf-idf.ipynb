import pandas as pd
# from math import log
import numpy as np


corpus = [
    '배우고 싶은 자연어',
    '배우고 싶은 딥러닝',
    '딥러닝 머신러닝 배우고 싶은 머신러닝',
    '자연어 처리 좋아요'
]


vocab = list(set([w for doc in corpus for w in doc.split()]))
vocab.sort()


vocab


N = len(vocab)
N


# 문서수
dc = len(corpus)

# 단어빈도
def tf(t, d):
    return d.count(t)

# Inverse-문서빈도
def idf(t) :
    df = 0
    for doc in corpus:
        df += t in doc
        
    # return  np.log( dc / (df + 1) )   
    return  np.log( (dc + 1) / (df + 1) ) + 1   # 전체문서수 / 단어가 등장하는 문서 수 

# 단어빈도 * Inverse-문서빈도 => 가중치
def tfidf(t, d):
    return tf(t,d) * idf(t)    


result = []
for i in range(dc) :
    result.append([])
    d = corpus[i]
    for j in range(len(vocab)) :
        t = vocab[j]
        result[-1].append(tf(t,d))

tf_ = pd.DataFrame(result, columns = vocab)   


tf_


result = []
for j in range(len(vocab)) :
    t = vocab[j]
    result.append(idf(t))

idf_ = pd.DataFrame(result, index=vocab, columns=['IDF'])
idf_


result = []
for i in range(dc) :
    result.append([])
    d = corpus[i]
    for j in range(len(vocab)) :
        t = vocab[j]
        result[-1].append(tfidf(t,d))
tfidf_ = pd.DataFrame(result, columns = vocab)
tfidf_


from sklearn.feature_extraction.text import TfidfVectorizer


TfidfVectorizer?


# TfidfVectorizer 초기화
tfidfvect = TfidfVectorizer(norm=None)  # norm=None으로 설정하여 정규화를 제거
tfidf_matrix = tfidfvect.fit_transform(corpus)

# 단어 목록
feature_names = tfidfvect.get_feature_names_out()

# 1. TF (Term Frequency) 계산
# TF를 얻기 위해 use_idf=False로 새로운 vectorizer 생성
tf_tfidfvect = TfidfVectorizer(use_idf=False, norm=None)
tf_matrix = tf_tfidfvect.fit_transform(corpus)
tf_values = pd.DataFrame(
    tf_matrix.toarray(),
    columns=feature_names,
    index=[f'문서_{i+1}' for i in range(len(corpus))]
)

# 2. IDF 값
idf_values = pd.Series(
    tfidfvect.idf_,
    index=feature_names
)

# 3. TF-IDF 값 (최종 결과)
tfidf_values = pd.DataFrame(
    tfidf_matrix.toarray(),
    columns=feature_names,
    index=[f'문서_{i+1}' for i in range(len(corpus))]
)

# 결과 출력
print("=== 1. TF (Term Frequency) 값 ===")
print(tf_values)
print("\n=== 2. IDF (Inverse Document Frequency) 값 ===")
print(idf_values)
print("\n=== 3. TF-IDF 값 (TF * IDF) ===")
print(tfidf_values)

# 계산 검증
print("\n=== 계산 검증 ===")
# 특정 단어에 대해 TF * IDF 계산이 TF-IDF와 일치하는지 확인
word = "파이썬"
if word in feature_names:
    print(word)
    for doc_idx in range(len(corpus)):
        tf = tf_values.iloc[doc_idx][word]
        idf = idf_values[word]
        tfidf = tfidf_values.iloc[doc_idx][word]
        print(f"\n문서_{doc_idx+1}의 '{word}' 단어:")
        print(f"TF: {tf:.4f}")
        print(f"IDF: {idf:.4f}")
        print(f"계산된 TF-IDF (TF * IDF): {tf * idf:.4f}")
        print(f"실제 TF-IDF 값: {tfidf:.4f}")


# 계산 검증
print("\n=== 계산 검증 ===")
# 특정 단어에 대해 TF * IDF 계산이 TF-IDF와 일치하는지 확인
word = "딥러닝"
if word in feature_names:
    print(word)
    for doc_idx in range(len(corpus)):
        tf = tf_values.iloc[doc_idx][word]
        idf = idf_values[word]
        tfidf = tfidf_values.iloc[doc_idx][word]
        print(f"\n문서_{doc_idx+1}의 '{word}' 단어:")
        print(f"TF: {tf:.4f}")
        print(f"IDF: {idf:.4f}")
        print(f"계산된 TF-IDF (TF * IDF): {tf * idf:.4f}")
        print(f"실제 TF-IDF 값: {tfidf:.4f}")



