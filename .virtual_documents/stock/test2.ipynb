import re


# http요청 응답, html 구문분석 패키지
import requests
from bs4 import BeautifulSoup


# 셀레니움 브라우저의 동작을 자동화 하는 패키지
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By


# 데이터 분석 패키지
import pandas as pd


url = 'https://finance.naver.com/sise/sise_group.naver?type=upjong'


# 브라우저 종료 방지 옵션
chrome_options = Options()
chrome_options.add_experimental_option('detach', True)
# 웹드라이버를 이용한 브라우저 제어
driver = webdriver.Chrome(options=chrome_options)

#페이지가 모두 로드될때 까지 최대 1초 대기
driver.implicitly_wait(1)


driver.get(url)


soup = BeautifulSoup(driver.page_source,'html.parser')


soup.select_one('#contentarea_left > table > tbody > tr:nth-child(4) > td.tc > div > div > span').text


pattern = re.compile(r'100%')
pattern.findall(driver.page_source)


ele = driver.find_element(By.CSS_SELECTOR,'#contentarea_left > table > tbody > tr:nth-child(4) > td.tc > div > div > span')


ele.text


from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
wait = WebDriverWait(driver, 3)
element = wait.until(
    EC.visibility_of_element_located((By.CSS_SELECTOR,
                                    '#contentarea_left > table > tbody > tr:nth-child(4) > td.tc > div > div > span'))
) 
element.text


driver.execute_script("return document.querySelector('#contentarea_left > table > tbody > tr:nth-child(4) > td.tc > div > div > span').textContent")



